{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "# Import some data to play with\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class Ensemble:\n",
    "    def __init__(self):\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def load_data(self, text, train):\n",
    "        s = np.loadtxt(text, dtype=np.float32, delimiter=' ')\n",
    "        end = s.shape[1] - 1\n",
    "        text_X = s[:, :end]\n",
    "        text_y = s[:, -1]\n",
    "        s = np.loadtxt(train, dtype=np.float32, delimiter=' ')\n",
    "        end = s.shape[1] - 1\n",
    "        train_X = s[:, :end]\n",
    "        train_y = s[:, -1]\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_X, text_X, train_y, text_y\n",
    "\n",
    "    @staticmethod\n",
    "    def __Classifiers__(name=None):\n",
    "        # See for reproducibility\n",
    "        random_state = 100\n",
    "        kernel = 1.0 * RBF(1.0)\n",
    "        if name == 'Neighbors':\n",
    "            return RadiusNeighborsClassifier(radius=1.0)\n",
    "        if name == 'Gaussian_Process':\n",
    "            return GaussianProcessClassifier(kernel=kernel, random_state=random_state)\n",
    "        if name == 'Gaussian_NB':\n",
    "            return GaussianNB()\n",
    "        if name == 'Bernoulli_NB':\n",
    "            return BernoulliNB()\n",
    "        if name == 'DecisionTree':\n",
    "            return tree.DecisionTreeClassifier()\n",
    "        if name == 'Bagging':\n",
    "            return BaggingClassifier(base_estimator=SVC())\n",
    "        if name == 'RandomForest':\n",
    "            return RandomForestClassifier(n_estimators=10)\n",
    "        if name == 'AdaBoost':\n",
    "            return AdaBoostClassifier(n_estimators=100, random_state=random_state)\n",
    "        if name == 'GradientBoosting':\n",
    "            return GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1,\n",
    "                                              random_state=random_state)\n",
    "        if name == 'HistGradientBoosting':\n",
    "            return HistGradientBoostingClassifier()\n",
    "        if name == 'MLP':\n",
    "            return MLPClassifier(random_state=random_state)\n",
    "\n",
    "    # 1.6.2\n",
    "    def __Neighbors__(self):\n",
    "        # Decision Tree Classifier\n",
    "        neigh = Ensemble.__Classifiers__(name='Neighbors')\n",
    "        # Init Grid Search\n",
    "        neigh.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.7.2\n",
    "    def __GPC__(self):\n",
    "        # Decision Tree Classifier\n",
    "        GPC = Ensemble.__Classifiers__(name='Gaussian_Process')\n",
    "        # Init Grid Search\n",
    "        GPC.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.9.1\n",
    "    def __Gaussian_NB__(self):\n",
    "        # Decision Tree Classifier\n",
    "        gnb = Ensemble.__Classifiers__(name='Gaussian_NB')\n",
    "        # Init Grid Search\n",
    "        gnb.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.9.4\n",
    "    def __Bernoulli_NB__(self):\n",
    "        # Decision Tree Classifier\n",
    "        bnb = Ensemble.__Classifiers__(name='Bernoulli_NB')\n",
    "        # Init Grid Search\n",
    "        bnb.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.10.1\n",
    "    def __DecisionTree__(self):\n",
    "        # Decision Tree Classifier\n",
    "        dt = Ensemble.__Classifiers__(name='DecisionTree')\n",
    "        # Init Grid Search\n",
    "        dt.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.11.1\n",
    "    def __Bagging__(self):\n",
    "        # Decision Tree Classifier\n",
    "        bag = Ensemble.__Classifiers__(name='Bagging')\n",
    "        # Init Grid Search\n",
    "        bag.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.11.2\n",
    "    def __RandomForest__(self):\n",
    "        # Decision Tree Classifier\n",
    "        Forest = Ensemble.__Classifiers__(name='RandomForest')\n",
    "        # Init Grid Search\n",
    "        Forest.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.11.3\n",
    "    def __AdaBoost__(self):\n",
    "        # Decision Tree Classifier\n",
    "        AdaBoost = Ensemble.__Classifiers__(name='AdaBoost')\n",
    "        # Init Grid Search\n",
    "        AdaBoost.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.11.4\n",
    "    def __GradientBoosting__(self):\n",
    "        # Decision Tree Classifier\n",
    "        Gdbt = Ensemble.__Classifiers__(name='GradientBoosting')\n",
    "        # Init Grid Search\n",
    "        Gdbt.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.11.5\n",
    "    def __HistGradientBoosting__(self):\n",
    "        # Decision Tree Classifier\n",
    "        HGdbt = Ensemble.__Classifiers__(name='HistGradientBoosting')\n",
    "        # Init Grid Search\n",
    "        HGdbt.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # 1.17.2\n",
    "    def __MLPClassifier_1__(self):\n",
    "        # Decision Tree Classifier\n",
    "        MLP = Ensemble.__Classifiers__(name='MLP')\n",
    "        # Init Grid Search\n",
    "        MLP.fit(self.x_train, self.y_train)\n",
    "\n",
    "    def __VotingClassifier__(self):\n",
    "\n",
    "        # Instantiate classifiers\n",
    "\n",
    "        #Neigh = Ensemble.__Classifiers__(name='Neighbors')\n",
    "        GPC = Ensemble.__Classifiers__(name='Gaussian_Process')\n",
    "        gnb = Ensemble.__Classifiers__(name='Gaussian_NB')\n",
    "        bnb = Ensemble.__Classifiers__(name='Bernoulli_NB')\n",
    "        dt = Ensemble.__Classifiers__(name='DecisionTree')\n",
    "        bag = Ensemble.__Classifiers__(name='Bagging')\n",
    "        Forest = Ensemble.__Classifiers__(name='RandomForest')\n",
    "        Ada = Ensemble.__Classifiers__(name='AdaBoost')\n",
    "        Gdbt = Ensemble.__Classifiers__(name='GradientBoosting')\n",
    "        HGdbt = Ensemble.__Classifiers__(name='HistGradientBoosting')\n",
    "        MLP = Ensemble.__Classifiers__(name='MLP')\n",
    "        # Voting Classifier initialization\n",
    "        vc = VotingClassifier(estimators=[('Gaussian_Process', GPC), ('Gaussian_NB', gnb),\n",
    "                                          ('Bernoulli_NB', bnb), ('DecisionTree', dt), ('Bagging', bag),\n",
    "                                          ('RandomForest', Forest), ('AdaBoost', Ada), ('GradientBoosting', Gdbt),\n",
    "                                          ('HistGradientBoosting', HGdbt), ('MLP', MLP)\n",
    "                                          ], voting='soft')\n",
    "        # Fitting the vc model\n",
    "        vc.fit(self.x_train, self.y_train)\n",
    "\n",
    "        return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train accuracy: 0.9703947368421053\n",
      "Test accuracy: 0.875\n",
      "评价指标:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.93        51\n",
      "         1.0       1.00      0.38      0.56        13\n",
      "\n",
      "    accuracy                           0.88        64\n",
      "   macro avg       0.93      0.69      0.74        64\n",
      "weighted avg       0.89      0.88      0.85        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  label       准确率       偏移值\n",
      "0             Neighbors  0.720273  0.032247\n",
      "1      Gaussian_Process  0.648087  0.021192\n",
      "2           Gaussian_NB  0.703880  0.050108\n",
      "3          Bernoulli_NB  0.644754  0.021845\n",
      "4          DecisionTree  0.736776  0.015777\n",
      "5               Bagging  0.704044  0.021982\n",
      "6          RandomForest  0.684317  0.035629\n",
      "7              AdaBoost  0.664536  0.044228\n",
      "8      GradientBoosting  0.703989  0.013711\n",
      "9  HistGradientBoosting  0.713607  0.064673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = '.\\\\test\\\\TAPE.txt'\n",
    "train = '.\\\\test\\\\TAPE.txt'\n",
    "ensemble = Ensemble()\n",
    "ensemble.load_data(text, train)\n",
    "model = ensemble.__VotingClassifier__()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save model\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = np.loadtxt(text, dtype=np.float32, delimiter=' ')\n",
    "end = s.shape[1] - 1\n",
    "text_X = s[:, :end]\n",
    "text_y = s[:, -1]\n",
    "# read model\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model1 = pickle.load(f)\n",
    "\n",
    "# predict\n",
    "result = model1.predict(text_X)\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}